{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e90f727f-d557-423b-a61f-d40d1b9a65da",
   "metadata": {},
   "source": [
    "# Deep Learning with Pytorch Tutorial Notebook\n",
    "[Video link to tutorial](https://www.youtube.com/watch?v=c36lUUr864M&ab_channel=PythonEngineer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31df10d-7a6e-46a5-bf35-2d6299946c0d",
   "metadata": {},
   "source": [
    "# Tutorial 2 - Tensor Basics\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f82ff9e-4c8c-4d86-bd77-575427fb3d3f",
   "metadata": {},
   "source": [
    "## Making tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdf8f7b0-012d-47fd-a7a9-8e616415520c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[7.0368e+28, 3.3127e-18, 2.5750e-12],\n",
      "         [7.1856e+22, 1.8609e+34, 1.8179e+31]],\n",
      "\n",
      "        [[1.8524e+28, 9.6647e+35, 2.0076e+29],\n",
      "         [7.3185e+28, 6.1948e-04, 1.1513e-38]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# create an empty tensor with dimensions (x,y,z)\n",
    "x = torch.empty(2, 2,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7af68b79-9741-4aa2-a09c-3474a3b2b319",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3311, 0.2828, 0.0576],\n",
      "        [0.9699, 0.7240, 0.9702]])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor with random values \n",
    "y = torch.rand(2,3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1e12342-8985-4a05-9c42-f8ac9e4a0239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor with zeros\n",
    "y = torch.zeros(2,3)\n",
    "print(y)\n",
    "\n",
    "# create a tensor with ones\n",
    "z = torch.ones(2,2)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee6e42c3-109b-47f7-9ad0-c64d73825f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# choose the data type for the tensor\n",
    "x = torch.ones(2,2, dtype=torch.int)\n",
    "print(x.dtype)\n",
    "\n",
    "# choose the data type for the tensor\n",
    "x = torch.ones(2,2, dtype=torch.float)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebb917b0-db37-4f28-bc41-88b679c9ebdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# looking at the size of a tensor\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b014cb32-57f8-4d81-8e31-9adf9809f535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 0.1000])\n"
     ]
    }
   ],
   "source": [
    "# making a tensor from a list\n",
    "x = torch.tensor([2.5, 0.1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15182d57-ec3d-4a96-852a-e48c35b18ee4",
   "metadata": {},
   "source": [
    "## Operations on tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef6f352d-79ad-49d3-bc11-39189248aafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3962, 0.5326],\n",
      "        [0.8929, 0.5876]])\n",
      "tensor([[0.2162, 0.8210],\n",
      "        [0.6164, 0.3422]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8979c50b-e414-4c06-9291-9149e62c86b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = tensor([[0.6124, 1.3536],\n",
      "        [1.5093, 0.9297]])\n",
      "z = tensor([[0.6124, 1.3536],\n",
      "        [1.5093, 0.9297]])\n",
      "tensor([[0.6124, 1.3536],\n",
      "        [1.5093, 0.9297]])\n"
     ]
    }
   ],
   "source": [
    "# addition method 1\n",
    "z = x + y\n",
    "print(f'z = {z}')\n",
    "\n",
    "# addition method 2\n",
    "z = torch.add(x,y)\n",
    "print(f'z = {z}')\n",
    "\n",
    "# addition method 3\n",
    "y.add_(x) # this modifies the variable it's applied on \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c97a9bea-3a47-47c7-941e-8a5b4e35ef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = tensor([[-0.2162, -0.8210],\n",
      "        [-0.6164, -0.3422]])\n",
      "z = tensor([[0.2426, 0.7209],\n",
      "        [1.3476, 0.5463]])\n",
      "z = tensor([[0.6470, 0.3935],\n",
      "        [0.5916, 0.6320]])\n"
     ]
    }
   ],
   "source": [
    "# subtraction \n",
    "z = x - y\n",
    "z = torch.sub(x,y)\n",
    "print(f'z = {z}')\n",
    "\n",
    "# multiplication\n",
    "z = torch.mul(x,y)\n",
    "print(f'z = {z}')\n",
    "\n",
    "# division\n",
    "z = torch.div(x,y)\n",
    "print(f'z = {z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9daba856-6b49-4939-845f-139c1ca855c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4828, 0.6357, 0.5744],\n",
      "        [0.8080, 0.7325, 0.3847],\n",
      "        [0.4489, 0.0291, 0.1722],\n",
      "        [0.8730, 0.6808, 0.6664],\n",
      "        [0.9501, 0.3304, 0.3911]])\n",
      "tensor([0.4828, 0.8080, 0.4489, 0.8730, 0.9501])\n",
      "tensor([0.8080, 0.7325, 0.3847])\n",
      "tensor(0.7325)\n",
      "0.7325420379638672\n"
     ]
    }
   ],
   "source": [
    "# slicing operations\n",
    "a = torch.rand(5,3)\n",
    "print(a)\n",
    "\n",
    "# get all rows, first column\n",
    "print(a[:, 0])\n",
    "\n",
    "# get first row, all columns \n",
    "print(a[1, :])\n",
    "\n",
    "# get element at 1,1 (returns a tensor)\n",
    "print(a[1,1])\n",
    "\n",
    "# get element at 1,1 and return item\n",
    "print(a[1,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31a9b796-ffb7-414f-829e-3aa45938452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3664, 0.6304, 0.6535, 0.6437],\n",
      "        [0.2842, 0.8478, 0.9061, 0.5782],\n",
      "        [0.0294, 0.8165, 0.2758, 0.7901],\n",
      "        [0.0335, 0.3574, 0.0256, 0.0384]])\n",
      "tensor([[0.3664],\n",
      "        [0.6304],\n",
      "        [0.6535],\n",
      "        [0.6437],\n",
      "        [0.2842],\n",
      "        [0.8478],\n",
      "        [0.9061],\n",
      "        [0.5782],\n",
      "        [0.0294],\n",
      "        [0.8165],\n",
      "        [0.2758],\n",
      "        [0.7901],\n",
      "        [0.0335],\n",
      "        [0.3574],\n",
      "        [0.0256],\n",
      "        [0.0384]])\n"
     ]
    }
   ],
   "source": [
    "# reshaping using view()\n",
    "x = torch.rand(4,4)\n",
    "print(x)\n",
    "y = x.view(-1, 1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0b4ea4-9942-4902-9c10-c3397ed33947",
   "metadata": {},
   "source": [
    "## Converting numpy to torch and vice versa\n",
    "Note: when working only on the CPU, numpy arrays and pytorch tensors will share the same place in memory. Therefore, editing one will edit the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ba2ec01-18d6-407b-bf39-2909fa23d4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "# convert from torch to numpy\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "23157abb-9d88-4072-9f77-9efd60dcb5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# convert from numpy to tensor\n",
    "c = np.ones(5)\n",
    "d = torch.from_numpy(c)\n",
    "print(d)\n",
    "print(type(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4debf4-5269-4015-adc5-c8bb53549822",
   "metadata": {},
   "source": [
    "## Requires grad\n",
    "This is a property of tensors that tells pytorch that the tensor will need to calculate gradients for optimization\n",
    "Whenever you have a variable in your model that you want to optimize, you need to set this parameter to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "360484f9-542b-477f-874c-a5703cd0fb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, requires_grad = True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cea792-9578-4fee-aa1a-363a1416841a",
   "metadata": {},
   "source": [
    "# Tutorial 3 - Autograd\n",
    "## Gradient Computation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f2bed8a5-5153-4f25-8c15-15b8d7288a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0072,  0.9425,  0.2594], requires_grad=True)\n",
      "tensor([1.9928, 2.9425, 2.2594], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad = True)\n",
    "print(x)\n",
    "\n",
    "# whenever we do operations with a tensor that has requires_grad = True, pytorch will create a computational graph \n",
    "y = x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e74e17-125d-44a1-b9fd-0abfc999a45d",
   "metadata": {},
   "source": [
    "Because the operation was an addition, pytorch creates a gradient function to use in backpropagation called \"AddBackward\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dd9e72f5-7643-4bf2-b0b9-50e76517292b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7.9426, 17.3170, 10.2094], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y*2\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237a9afd-da88-4f00-9650-6e33bec4bd0d",
   "metadata": {},
   "source": [
    "Here our gradient function is \"MulBackward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e1c1187a-f382-4627-aa74-f279db8f6521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.8230, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = z.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b393a2-7900-4528-a3b2-64f52f8155dc",
   "metadata": {},
   "source": [
    "Here our gradient function is \"MeanBackward\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af900f31-02ff-45f7-82d6-342b013d080b",
   "metadata": {},
   "source": [
    "## Calculating the gradient of a tensor\n",
    "By using the backward() function, we can calculate the derivative dz/dx <br>\n",
    "The backward() function is computing the jacobian product (chain rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d1096b3a-c6c5-4ea6-9c04-f55329bc1b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6571, 3.9234, 3.0125])\n"
     ]
    }
   ],
   "source": [
    "z.backward() # dz/dx\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f69afe-7cad-4a7c-b0e5-181c9e97775f",
   "metadata": {},
   "source": [
    "In the case where z is a scalar value, we can implicitly call the backward() function. <br>\n",
    "However, when z is a vector, we must pass a vector into backward() for it to properly calculate the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "83eff3da-b78d-433d-b39c-7a38bf10a5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.2513, 27.4636,  3.0306])\n"
     ]
    }
   ],
   "source": [
    "z = y*y*2\n",
    "v = torch.tensor([0.1, 1.0, 0.001], dtype = torch.float32)\n",
    "z.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621a0019-4472-42bd-8e1b-d31bfc8a60d6",
   "metadata": {},
   "source": [
    "## How to prevent gradient tracking\n",
    "This is useful for intermediate steps in an algorithm where we don't want to be calculating gradients and tracking the history of a gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9a420800-ecb2-4828-b912-27ae010c3df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0072,  0.9425,  0.2594])\n",
      "tensor([-0.0072,  0.9425,  0.2594])\n",
      "tensor([-0.0072,  0.9425,  0.2594])\n"
     ]
    }
   ],
   "source": [
    "# first method\n",
    "x.requires_grad_(False)\n",
    "print(x)\n",
    "\n",
    "# second method\n",
    "x.detach()\n",
    "print(x)\n",
    "\n",
    "# third method\n",
    "with torch.no_grad():\n",
    "    # operations here\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8e212-2fd4-4f58-b46e-391b50b36ade",
   "metadata": {},
   "source": [
    "### Dummy training example\n",
    "This will be to visualize the issues that can arise if you don't prevent gradient tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7f2e7cc1-3f37-4413-a7b0-1f9c1feacfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad = True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    \n",
    "    print(weights.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c8346-48f7-434c-9594-667b115a659c",
   "metadata": {},
   "source": [
    "You can see above that without resetting gradient values, the gradients are aggregated over time and give erroneous values for the gradients <br>\n",
    "The gradients should remain at 3 (since we are doing the operatoin weights * 3), but they are aggregating instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "31121889-11ba-4e99-8b74-440a35b29bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad = True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    \n",
    "    print(weights.grad)\n",
    "    \n",
    "    # here we reset the gradients so that they don't carry over in each iteration, always providing the correct gradient of 3\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c285555-3c6a-4382-9183-99c41b3cd607",
   "metadata": {},
   "source": [
    "Whenever we want to calculate gradients, we must set \"requires_grad = True\" within our tensor. <br>\n",
    "Then, we can calculate the gradient by calling the \"backward()\" function <br>\n",
    "And in each iteration of our optimization steps, we must call the \"x.grad.zero_()\" function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99b24a-6ae6-42e7-b39f-b4bcf15aa3d0",
   "metadata": {},
   "source": [
    "# Tutorial 4 - Backpropagation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8e7ff-36cd-4da8-a2a3-00a1703d076d",
   "metadata": {},
   "source": [
    "## Chain Rule\n",
    "Backpropagation is modeled under the idea that we have a lot of chained operations taking an initial input x and leading to a final output z, and we want to minimize the value of z. <br>\n",
    "Say we have: <br>\n",
    "x -> a(x) = y, y-> b(y) = z <br>\n",
    "To compute dz/dx, we can use the chain rule as follows: <br>\n",
    "dz/dx = dz/dy * dy/dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331a96dd-f21e-4b6f-8284-1a12534e20b6",
   "metadata": {},
   "source": [
    "## Computational Graph \n",
    "With every operation we do, pytorch computes a Computational Graph <br>\n",
    "At each node, we apply one operation or function to get an output. <br>\n",
    "These nodes compute \"Local Gradients\" which can later be used with the chain rule to compute a total gradient such as the dLoss / dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b0563-3d18-4f04-abcc-fb0d3956f290",
   "metadata": {},
   "source": [
    "## The steps of Backpropagation\n",
    "1. **Forward pass**: Compute Loss\n",
    "2. Compute **local gradients**\n",
    "3. **Backward pass**: Compute dLoss / dWeights using the chain rule "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e696fba-29e4-46a7-b9fa-f6edd7773834",
   "metadata": {},
   "source": [
    "Lets do a simple example of backpropagation using a linear regression model, trying to optimize a weight to minimize the loss function <br>\n",
    "x = 1, y = 2, w = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "28e3513b-7fb0-485e-a03a-b35afdf41029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0\n",
      "gradient: -2.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "w = torch.tensor(1.0, requires_grad = True)\n",
    "\n",
    "# forward pass, compute loss\n",
    "y_hat = w * x\n",
    "loss = (y_hat - y)**2\n",
    "print(f'loss: {loss}')\n",
    "\n",
    "# backward pass (this step actually includes steps 2 and 3 above, since it automatically computes local gradients)\n",
    "loss.backward()\n",
    "print(f'gradient: {w.grad}')\n",
    "\n",
    "# update weights ...\n",
    "# next forward and backward pass ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ba9ad5-67bb-4bfe-b7d2-e335d61f678b",
   "metadata": {},
   "source": [
    "This is in a nutshell how backpropagation works, and this will be the backbone to algorithms such as gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b04099e-6976-4af3-bd6b-ab5aad96a985",
   "metadata": {},
   "source": [
    "# Tutorial 5 - Gradient Descent using Autograd\n",
    "---\n",
    "In this tutorial, we will first set up a gradient descent pipeline manually, and then we'll see how we can replace the manual operations with autograd functions to achieve the same result. <br>\n",
    "The model we'll be using is a linear regression model.\n",
    "## Pipeline\n",
    "1. Prediction *pytorch model*\n",
    "2. **Gradients computation *autograd***\n",
    "3. Loss Computation *Pytorch loss*\n",
    "4. Parameter updates: *Pytorch optimizer*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e75c94-443e-4ae5-b554-2ee4794306a4",
   "metadata": {},
   "source": [
    "## 1. Manual Gradient Descent\n",
    "Using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "261d3f8b-5107-4e5c-82ae-706be195e02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training: f(5) = 0.000\n",
      "epoch: 1, weight: 1.200, loss: 30.00000000\n",
      "epoch: 2, weight: 1.680, loss: 4.79999924\n",
      "epoch: 3, weight: 1.872, loss: 0.76800019\n",
      "epoch: 4, weight: 1.949, loss: 0.12288000\n",
      "epoch: 5, weight: 1.980, loss: 0.01966083\n",
      "epoch: 6, weight: 1.992, loss: 0.00314570\n",
      "epoch: 7, weight: 1.997, loss: 0.00050332\n",
      "epoch: 8, weight: 1.999, loss: 0.00008053\n",
      "epoch: 9, weight: 1.999, loss: 0.00001288\n",
      "epoch: 10, weight: 2.000, loss: 0.00000206\n",
      "epoch: 11, weight: 2.000, loss: 0.00000033\n",
      "epoch: 12, weight: 2.000, loss: 0.00000005\n",
      "epoch: 13, weight: 2.000, loss: 0.00000001\n",
      "epoch: 14, weight: 2.000, loss: 0.00000000\n",
      "epoch: 15, weight: 2.000, loss: 0.00000000\n",
      "epoch: 16, weight: 2.000, loss: 0.00000000\n",
      "epoch: 17, weight: 2.000, loss: 0.00000000\n",
      "epoch: 18, weight: 2.000, loss: 0.00000000\n",
      "epoch: 19, weight: 2.000, loss: 0.00000000\n",
      "epoch: 20, weight: 2.000, loss: 0.00000000\n",
      "prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x \n",
    "X = np.array([1, 2, 3, 4], dtype = np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype = np.float32)\n",
    "\n",
    "w = 0.0\n",
    "\n",
    "# model prediction \n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "# gradients\n",
    "# MSE = 1 / N * (w*x - y)**2\n",
    "# dJ/dw = 1 / N 2x (w*x - y)\n",
    "def gradient(x, y, y_pred):\n",
    "    return np.dot(2*x, y_pred - y).mean()\n",
    "\n",
    "print(f'prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "    \n",
    "    # update weights\n",
    "    w -= learning_rate * dw\n",
    "    \n",
    "    print(f'epoch: {epoch+1}, weight: {w:.3f}, loss: {l:.8f}')\n",
    "\n",
    "print(f'prediction after training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6177443a-1086-4734-aa1d-0767e8b80e74",
   "metadata": {},
   "source": [
    "## 2. Automatic Gradient Descent\n",
    "Using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6c319569-6616-4cb2-8c05-21c9b8acac5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training: f(5) = 0.000\n",
      "epoch: 1, weight: 0.300, loss: 30.00000000\n",
      "epoch: 11, weight: 1.665, loss: 1.16278565\n",
      "epoch: 21, weight: 1.934, loss: 0.04506890\n",
      "epoch: 31, weight: 1.987, loss: 0.00174685\n",
      "epoch: 41, weight: 1.997, loss: 0.00006770\n",
      "epoch: 51, weight: 1.999, loss: 0.00000262\n",
      "epoch: 61, weight: 2.000, loss: 0.00000010\n",
      "epoch: 71, weight: 2.000, loss: 0.00000000\n",
      "epoch: 81, weight: 2.000, loss: 0.00000000\n",
      "epoch: 91, weight: 2.000, loss: 0.00000000\n",
      "prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x \n",
    "X = torch.tensor([1, 2, 3, 4], dtype = torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype = torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True)\n",
    "\n",
    "# model prediction \n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "\n",
    "print(f'prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass with autograd\n",
    "    # this calculates dl/dw\n",
    "    l.backward()\n",
    "    \n",
    "    # update weights\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "    \n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, weight: {w:.3f}, loss: {l:.8f}')\n",
    "\n",
    "print(f'prediction after training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbbeeb1-d59a-4904-b1bf-ef6b164e5a67",
   "metadata": {},
   "source": [
    "In this case, we've changed the training loop to compute gradients through the use of the \"backward()\" function which calculates dl/dw and saves the gradients in w.grad <br>\n",
    "We also made sure to zero the gradients after every pass of the training loop to ensure no aggregation of gradients is done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e0b104-ce42-4d9c-929a-ee864e4b7abc",
   "metadata": {},
   "source": [
    "# Tutorial 6 - Training Pipeline\n",
    "## Model / Loss / Optimizer\n",
    "---\n",
    "## Pipeline\n",
    "1. **Prediction *pytorch model***\n",
    "2. Gradients computation *autograd*\n",
    "3. **Loss Computation *Pytorch loss***\n",
    "4. **Parameter updates: *Pytorch optimizer***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a265a1d3-23ed-433e-aacd-a0ae508fdbdb",
   "metadata": {},
   "source": [
    "## 3. Automatic Loss and Optimization\n",
    "Using pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046867e5-6d98-42d4-8f93-99c4c0943a4d",
   "metadata": {},
   "source": [
    "## General PyTorch Pipeline\n",
    "1. Design model (input, output size, forward pass)\n",
    "2. Construct loss and optimizer\n",
    "3. Training loop \n",
    "     - forward pass: compute prediction\n",
    "     - backward pass: gradients\n",
    "     - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f586b449-0385-456c-bd19-f4f8088f5cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training: f(5) = 0.000\n",
      "epoch: 1, weight: 0.300, loss: 30.00000000\n",
      "epoch: 11, weight: 1.665, loss: 1.16278565\n",
      "epoch: 21, weight: 1.934, loss: 0.04506890\n",
      "epoch: 31, weight: 1.987, loss: 0.00174685\n",
      "epoch: 41, weight: 1.997, loss: 0.00006770\n",
      "epoch: 51, weight: 1.999, loss: 0.00000262\n",
      "epoch: 61, weight: 2.000, loss: 0.00000010\n",
      "epoch: 71, weight: 2.000, loss: 0.00000000\n",
      "epoch: 81, weight: 2.000, loss: 0.00000000\n",
      "epoch: 91, weight: 2.000, loss: 0.00000000\n",
      "prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x \n",
    "X = torch.tensor([1, 2, 3, 4], dtype = torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype = torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True)\n",
    "\n",
    "# model prediction \n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "print(f'prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass with autograd\n",
    "    # this calculates dl/dw\n",
    "    l.backward()\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, weight: {w:.3f}, loss: {l:.8f}')\n",
    "\n",
    "print(f'prediction after training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd74ddb-00ea-4498-97c4-092eb869f84e",
   "metadata": {},
   "source": [
    "## 4. Automatic Forward Method\n",
    "Using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "abb5f9c2-0514-47a6-b384-8d382692138a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "prediction before training: f(5) = 1.035\n",
      "epoch: 1, weight: 0.425, loss: 23.30641174\n",
      "epoch: 11, weight: 1.536, loss: 0.69283772\n",
      "epoch: 21, weight: 1.721, loss: 0.10254128\n",
      "epoch: 31, weight: 1.757, loss: 0.08234382\n",
      "epoch: 41, weight: 1.769, loss: 0.07718282\n",
      "epoch: 51, weight: 1.776, loss: 0.07268082\n",
      "epoch: 61, weight: 1.783, loss: 0.06845021\n",
      "epoch: 71, weight: 1.789, loss: 0.06446603\n",
      "epoch: 81, weight: 1.796, loss: 0.06071371\n",
      "epoch: 91, weight: 1.802, loss: 0.05717989\n",
      "prediction after training: f(5) = 9.602\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x \n",
    "X = torch.tensor([1, 2, 3, 4], dtype = torch.float32).view(-1, 1)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype = torch.float32).view(-1,1)\n",
    "\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# making a custom model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "print(f'prediction before training: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass with autograd\n",
    "    # this calculates dl/dw\n",
    "    l.backward()\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f'epoch: {epoch+1}, weight: {w[0][0].item():.3f}, loss: {l:.8f}')\n",
    "\n",
    "print(f'prediction after training: f(5) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed285d-a997-43ce-b36a-a7aad28422b0",
   "metadata": {},
   "source": [
    "# Tutorial 7 - Linear Regression\n",
    "---\n",
    "1. Design model (input, output size, forward pass)\n",
    "2. Construct loss and optimizer\n",
    "3. Training loop \n",
    "     - forward pass: compute prediction\n",
    "     - backward pass: gradients\n",
    "     - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e668187f-2d15-405e-9616-d062d8587663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 0. prepare data\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features = 1, noise = 20, random_state = 1)\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# 1. model\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 2. define loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# 3. training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # forward pass and loss\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y)\n",
    "    \n",
    "    # backard pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if(epoch + 1 % 10 == 0):\n",
    "        [w,b] = model.parameters()\n",
    "        print(f'epoch: {epoch+1}, weight: {w[0][0].item():.3f}, loss: {loss.item():.4f}')\n",
    "        \n",
    "# plot \n",
    "predicted = model(X).detach().numpy()\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4b612d-8d11-4918-b925-a0a419190376",
   "metadata": {},
   "source": [
    "# Tutorial 8 - Logistic Regression\n",
    "---\n",
    "1. Design model (input, output size, forward pass)\n",
    "2. Construct loss and optimizer\n",
    "3. Training loop \n",
    "     - forward pass: compute prediction\n",
    "     - backward pass: gradients\n",
    "     - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7337d5ee-b3ca-4d1a-adfa-be840efcb026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d04c048-4b63-4687-b123-b7e7ec96d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) prepare data\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "# 569 samples, 30 features\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)\n",
    "\n",
    "# scale features\n",
    "sc = StandardScaler() # ensures all features have mean = 0, univariance. This is recommended for logistic regression\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# convert to torch tensors\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "# reshape y tensors to make them into column vectors\n",
    "y_train = y_train.view(-1,1)\n",
    "y_test = y_test.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f77478f-cca3-4cc9-8f51-aa836df19da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) model\n",
    "# f = wx + b, sigmoid at the end\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted\n",
    "    \n",
    "model = LogisticRegression(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01df567a-2e80-4f5a-86e2-c9318a341140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf68b29d-be1d-435b-82e4-5964b57ddcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss = 0.5060\n",
      "epoch: 20, loss = 0.4360\n",
      "epoch: 30, loss = 0.3881\n",
      "epoch: 40, loss = 0.3527\n",
      "epoch: 50, loss = 0.3254\n",
      "epoch: 60, loss = 0.3035\n",
      "epoch: 70, loss = 0.2855\n",
      "epoch: 80, loss = 0.2703\n",
      "epoch: 90, loss = 0.2573\n",
      "epoch: 100, loss = 0.2459\n"
     ]
    }
   ],
   "source": [
    "# 3) training loop\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # forward pass and loss\n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "    \n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # updates\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # print some information\n",
    "    if (epoch + 1)%10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc889bb2-77c7-4167-bec0-d389bd627681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8860\n"
     ]
    }
   ],
   "source": [
    "# evaluation of model\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()   # this rounds the sigmoid values between 0 and 1 to just be 0 or 1\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy = {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6ac062-d267-491f-af1d-30861075bb6d",
   "metadata": {},
   "source": [
    "# Tutorial 9 - Dataset & DataLoader\n",
    "---\n",
    "Some important terminology: <br>\n",
    "**Epoch**: 1 forward and backward pass of ALL training samples <br>\n",
    "**Batch size**: Number of training samples in one forward and backward pass <br>\n",
    "**Number of iterations**: Number of passes, each pass using \"batch_size\" number of samples <br>\n",
    "*e.g. 100 samples, batch_size= 20 --> 100/20 = 5 iterations for 1 epoch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ccb5ab9-8a4c-42ac-9d81-338e39f9069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba761214-5d03-4ddb-88d7-584648539a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset\n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        xy = np.loadtxt('./wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:, 1:])\n",
    "        self.y = torch.from_numpy(xy[:, [0]]) # n_samples, 1 \n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ad7e47a-fa73-4680-8ad4-da851a97e7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "555ea0d0-9878-42bb-9e2c-2c4ceadd5e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3580e+01, 2.5800e+00, 2.6900e+00, 2.4500e+01, 1.0500e+02, 1.5500e+00,\n",
      "         8.4000e-01, 3.9000e-01, 1.5400e+00, 8.6600e+00, 7.4000e-01, 1.8000e+00,\n",
      "         7.5000e+02],\n",
      "        [1.3860e+01, 1.3500e+00, 2.2700e+00, 1.6000e+01, 9.8000e+01, 2.9800e+00,\n",
      "         3.1500e+00, 2.2000e-01, 1.8500e+00, 7.2200e+00, 1.0100e+00, 3.5500e+00,\n",
      "         1.0450e+03],\n",
      "        [1.3490e+01, 1.6600e+00, 2.2400e+00, 2.4000e+01, 8.7000e+01, 1.8800e+00,\n",
      "         1.8400e+00, 2.7000e-01, 1.0300e+00, 3.7400e+00, 9.8000e-01, 2.7800e+00,\n",
      "         4.7200e+02],\n",
      "        [1.1460e+01, 3.7400e+00, 1.8200e+00, 1.9500e+01, 1.0700e+02, 3.1800e+00,\n",
      "         2.5800e+00, 2.4000e-01, 3.5800e+00, 2.9000e+00, 7.5000e-01, 2.8100e+00,\n",
      "         5.6200e+02]]) tensor([[3.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "# using data loader\n",
    "dataloader = DataLoader(dataset = dataset, batch_size = 4, shuffle = True)\n",
    "\n",
    "# creating an iterator\n",
    "dataiter = iter(dataloader)\n",
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9945d74-dfa7-4569-bb07-0f3fc860d8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/2, step 5/45, inputs = torch.Size([4, 13])\n",
      "epoch 1/2, step 10/45, inputs = torch.Size([4, 13])\n",
      "epoch 1/2, step 15/45, inputs = torch.Size([4, 13])\n",
      "epoch 1/2, step 20/45, inputs = torch.Size([4, 13])\n",
      "epoch 1/2, step 25/45, inputs = torch.Size([4, 13])\n",
      "epoch 1/2, step 30/45, inputs = torch.Size([4, 13])\n",
      "epoch 1/2, step 35/45, inputs = torch.Size([4, 13])\n",
      "epoch 1/2, step 40/45, inputs = torch.Size([4, 13])\n",
      "epoch 1/2, step 45/45, inputs = torch.Size([2, 13])\n",
      "epoch 2/2, step 5/45, inputs = torch.Size([4, 13])\n",
      "epoch 2/2, step 10/45, inputs = torch.Size([4, 13])\n",
      "epoch 2/2, step 15/45, inputs = torch.Size([4, 13])\n",
      "epoch 2/2, step 20/45, inputs = torch.Size([4, 13])\n",
      "epoch 2/2, step 25/45, inputs = torch.Size([4, 13])\n",
      "epoch 2/2, step 30/45, inputs = torch.Size([4, 13])\n",
      "epoch 2/2, step 35/45, inputs = torch.Size([4, 13])\n",
      "epoch 2/2, step 40/45, inputs = torch.Size([4, 13])\n",
      "epoch 2/2, step 45/45, inputs = torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "# dummy training loop \n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations =math.ceil(total_samples / 4)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        # forward pass\n",
    "        if (i+1)%5 == 0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs = {inputs.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a55cc01-0ddd-4338-8d9f-28f8fe2ce90a",
   "metadata": {},
   "source": [
    "# Tutorial 10 - Dataset Transformations\n",
    "## torchvision.transforms\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7678b6d-563d-47f3-9952-ff087cfe301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a107443a-579f-4ae8-ac30-7ea022adf028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset with transformations\n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, transform = None):\n",
    "        # data loading\n",
    "        xy = np.loadtxt('./wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.x = xy[:, 1:]\n",
    "        self.y = xy[:, [0]] # n_samples, 1 \n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f76d25f0-f59b-4aaa-8d2c-94656f5c9c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom transformation class 1\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65ee90c4-a398-4bc6-95f3-53d390fdbe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# applying our custom transform to dataset\n",
    "dataset = WineDataset(transform=ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b3f8065-d819-4aab-93f0-1bc7d50fc939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom transformation class 2\n",
    "class MulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        inputs, target = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e338eb7-3278-4ef2-88ec-6dd635414b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
      "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
      "        2.1300e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "# applying compose transform\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
    "dataset = WineDataset(transform = composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aac505-8332-46a0-b583-73415d5a39fa",
   "metadata": {},
   "source": [
    "# Tutorial 11 - Softmax & Cross Entropy\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb318bbd-da8c-4eea-8d7f-d0318bba41e8",
   "metadata": {},
   "source": [
    "## The softmax layer\n",
    "Softmax is a function used to squash values into probabilities from 0 to 1, where all of the softmax outputs sum up to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4869de28-6590-43da-8985-cb5b152b9f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax numpy:  [0.65900114 0.24243297 0.09856589]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# softmax in numpy\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "outputs = softmax(x)\n",
    "print('softmax numpy: ', outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be31c08f-3b9d-4b19-acd8-4339e4d2bb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "# softmax in pytorch\n",
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim=0)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c43204-5a1e-4486-9258-929994482221",
   "metadata": {},
   "source": [
    "## Cross-Entropy\n",
    "The softmax layer is usually combined with cross-entropy to calculate loss from the predictions made by softmax. <br>\n",
    "This measures the performance of our classification model, and can be used in multi-class models <br>\n",
    "The closer the prediction, the lower the cross-entropy loss. <br>\n",
    "> Note: Class labels must be One-Hot Encoded. e.g. if you have three categories of a class, you must encode them as [1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "017b4373-4d43-4387-81a5-38907847b877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1 numpy: 0.3567\n",
      "Loss2 numpy: 2.3026\n"
     ]
    }
   ],
   "source": [
    "# cross-entropy in numpy\n",
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss\n",
    "\n",
    "Y = np.array([1,0,0])\n",
    "\n",
    "# y_pred has probabilities\n",
    "y_pred_good = np.array([.7, .2, .1])\n",
    "y_pred_bad = np.array([.1, .3, .6])\n",
    "l1 = cross_entropy(Y, y_pred_good)\n",
    "l2 = cross_entropy(Y, y_pred_bad)\n",
    "\n",
    "print(f'Loss1 numpy: {l1:.4f}')\n",
    "print(f'Loss2 numpy: {l2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f48294e4-4b29-456a-b57b-44d2ce8afe62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1 pytorch: 0.4170\n",
      "Loss2 pytorch: 1.8406\n"
     ]
    }
   ],
   "source": [
    "# cross-entropy in pytorch\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# careful! cross entropy loss applies nn.LogSoftmax + nn.NLLLoss\n",
    "# Y has class labels, not one hot\n",
    "# Y_pred has raw scores (logits), no softmax\n",
    "Y = torch.tensor([0])\n",
    "# nsamples x nclasses = 1 x 3 = 3\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "\n",
    "# compute loss\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(f'Loss1 pytorch: {l1:.4f}')\n",
    "print(f'Loss2 pytorch: {l2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1aecb671-b899-4d6d-af0b-83e73d8d0d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred 1: tensor([0])\n",
      "Pred 2: tensor([1])\n"
     ]
    }
   ],
   "source": [
    "# get actual predictions\n",
    "_, prediction1 = torch.max(Y_pred_good, 1)\n",
    "_, prediction2 = torch.max(Y_pred_bad, 1)\n",
    "\n",
    "print(f'Pred 1: {prediction1}')\n",
    "print(f'Pred 2: {prediction2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebfe35f-eebe-4ed9-a3ab-88788aa0d805",
   "metadata": {},
   "source": [
    "## Typical neural net with softmax\n",
    "input layer -> hidden layers -> linear layer -> softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23901647-ee06-4ca0-8b49-5978b2303eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification\n",
    "class NeuralNet1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet1, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # sigmoid at the end\n",
    "        y_pred = torch.sigmoid(out)\n",
    "        return y_pred\n",
    "\n",
    "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa993f8e-548a-4db5-84eb-80d7ddd1f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass problem\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # no softmax at the end\n",
    "        return out\n",
    "\n",
    "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
    "criterion = nn.CrossEntropyLoss()  # (applies Softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832414d0-100a-4cbe-bb9d-1866907c4813",
   "metadata": {},
   "source": [
    "# Tutorial 12 - Activation Functions\n",
    "---\n",
    "Activation functions apply a non-linear transformation and decide whether a neuron should be activated or not. <br>\n",
    "> Without activation functions our network is basically just a stacked linear regression model <br>\n",
    "After each layer we typically use an activation function for the network to learn better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efccffbb-88ba-4581-86bb-badd10df286f",
   "metadata": {},
   "source": [
    "## Most popular activation functions\n",
    "1. **Step function**\n",
    "- f(x) = 1  if x >= theta where theta is a threshold, f(x) = 0 otherwise\n",
    "- Not used in practice\n",
    "2. **Sigmoid**\n",
    "- f(x)= 1 / 1 + e^-x\n",
    "- Will output a probability between 0 and 1\n",
    "- Usually used in the last layer of a binary classification problem\n",
    "3. **TanH**\n",
    "- f(x) = (2 / 1 + e^-2x) - 1\n",
    "- Used in hidden layers\n",
    "4. **ReLU**\n",
    "- f(x) = max(0, x)\n",
    "- If you don't know what to use, just use ReLU for hidden layers\n",
    "5. **Leaky ReLU**\n",
    "- f(x) = x if x >= 0, f(x) = a*x otherwise\n",
    "- Improved version of ReLU. Tries to solve the vanishing gradient problem\n",
    "6. **Softmax**\n",
    "- S(yi) = e^yi / sum(e^yi) \n",
    "- Good in last layer in multi class classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e3d92-4704-479a-b02f-66af9bec4f5a",
   "metadata": {},
   "source": [
    "## Using activation functions in pytorch\n",
    "### Option 1: Creating nn modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da502347-f9a3-4a5d-b1a9-bc00a1c49e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6cdbde39-23bd-405f-b62b-c7f4b96bd0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082ecb7f-a1d3-4156-9521-e8fd30f928c8",
   "metadata": {},
   "source": [
    "### Option 2: Use activations directly in forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b9605c9-3562-4891-80bb-a23be8203bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.linear1(x))\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2812ea3c-5ec9-4cdd-bd90-c0561faeb535",
   "metadata": {},
   "source": [
    "# Tutorial 13 - Feed-Forward Neural Net\n",
    "---\n",
    "Here we will create a neural network capable of digit classification using the MNIST dataset <br>\n",
    "This will use a lot of previous concepts, such as <br>\n",
    "1. DataLoader, Transformation\n",
    "2. Multilayer Neural Net, activation functions\n",
    "3. Loss and optimizer\n",
    "4. Training loop (batch training)\n",
    "5. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c25fea72-2f10-4a1d-bd2c-2f19046b6478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "64323c27-9500-4570-a486-786dbd852ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device config\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a316c1bf-e544-47d8-8f24-a33202262e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "input_size = 784 # images are sized 28x28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa0a3ef-d554-4375-89fc-34a69a82f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MNIST data\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, \n",
    "                                           transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, \n",
    "                                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c86a01fc-f811-40fe-b3f2-d0756e7cbfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# create dataloader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size = batch_size,\n",
    "                                          shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size = batch_size,\n",
    "                                          shuffle = False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df5376b-7b95-46eb-9d41-71db1dfc70ef",
   "metadata": {},
   "source": [
    "Above, we can see the samples shape as follows: 100 samples, 1 color channel, 28 pixels wide, 28 pixes long. <br>\n",
    "The labels shape is 100 because each sample has a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "742ae5ee-a606-4414-b631-0c4042e8614f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot data\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9c32b1f-8061-4f65-a2cb-fb1b53c49d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the neural network\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "243f6046-83fb-497d-be61-d6bdded3cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()     # this will apply the softmax for us\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9b5bdeb-5507-41a5-ae4b-5c40eda4d4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/2, step 100/600, loss = 0.3827\n",
      "epoch 1/2, step 200/600, loss = 0.3494\n",
      "epoch 1/2, step 300/600, loss = 0.2614\n",
      "epoch 1/2, step 400/600, loss = 0.2013\n",
      "epoch 1/2, step 500/600, loss = 0.3107\n",
      "epoch 1/2, step 600/600, loss = 0.2075\n",
      "epoch 2/2, step 100/600, loss = 0.2530\n",
      "epoch 2/2, step 200/600, loss = 0.2593\n",
      "epoch 2/2, step 300/600, loss = 0.2215\n",
      "epoch 2/2, step 400/600, loss = 0.1483\n",
      "epoch 2/2, step 500/600, loss = 0.1287\n",
      "epoch 2/2, step 600/600, loss = 0.1459\n",
      "accuracy = 95.27\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # images are 100,1,28,28\n",
    "        # input size is 784\n",
    "        # needs to be 100,784\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss\n",
    "        if (i+1)%100 == 0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
    "            \n",
    "# testing and evaluation\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # torch.max returns value, index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779249b4-4e21-4da7-9ae7-9e2c85d34d41",
   "metadata": {},
   "source": [
    "# Tutorial 14 - Convolutional Neural Net (CNN)\n",
    "---\n",
    "Here we will create a convolutional neural network capable of classification using the CIFAR-10 dataset <br>\n",
    "- Conv nets mainly work on image data and apply convolutional filters, pooling layers\n",
    "- These layers are used to learn features from images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e37d8-126a-4a95-847a-0c3a1f49723e",
   "metadata": {},
   "source": [
    "## Max Pooling\n",
    "- Max pooling is used to downsample an image by applying a max filter to subregions\n",
    "- In each subregion, write the maximum value into the output value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d693c1b-e25c-4b19-a8ba-e6e0c4772e73",
   "metadata": {},
   "source": [
    "### Convolutional Layer calculation\n",
    "To find the size of a resulting image after applying a convolutional layer, use <br>\n",
    "(W-F + 2P) / S + 1 <br>\n",
    "where: <br>\n",
    "- W = input image width\n",
    "- F = filter size\n",
    "- P = padding\n",
    "- S = stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "21150f20-b380-4d5d-a7af-632200f5d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0916df1-11ee-4ea1-af8b-ac67e792d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device config\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e76af9ae-0035-44cd-b8e4-4879b243b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "num_epochs = 4\n",
    "batch_size = 4\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685842f7-f4d9-4501-b39b-8295af8ee670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset has PILImage images of range [0,1]\n",
    "# we transform them to tensors of normalized range [-1,1]\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d5b85fe-cace-4cc6-bdc4-5f63621f0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "90ccc547-92de-4701-9757-687901a16198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the cnn\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c44c3610-958a-425c-ab60-93a9fce585a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f9011625-33f2-481e-ba80-bf48c43691ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [2000/12500], Loss: 2.3342\n",
      "Epoch [1/4], Step [4000/12500], Loss: 2.2990\n",
      "Epoch [1/4], Step [6000/12500], Loss: 2.3011\n",
      "Epoch [1/4], Step [8000/12500], Loss: 2.3143\n",
      "Epoch [1/4], Step [10000/12500], Loss: 2.1624\n",
      "Epoch [1/4], Step [12000/12500], Loss: 2.1353\n",
      "Epoch [2/4], Step [2000/12500], Loss: 1.9660\n",
      "Epoch [2/4], Step [4000/12500], Loss: 1.7241\n",
      "Epoch [2/4], Step [6000/12500], Loss: 2.3641\n",
      "Epoch [2/4], Step [8000/12500], Loss: 1.8526\n",
      "Epoch [2/4], Step [10000/12500], Loss: 2.4183\n",
      "Epoch [2/4], Step [12000/12500], Loss: 1.7807\n",
      "Epoch [3/4], Step [2000/12500], Loss: 1.9311\n",
      "Epoch [3/4], Step [4000/12500], Loss: 1.7577\n",
      "Epoch [3/4], Step [6000/12500], Loss: 1.4438\n",
      "Epoch [3/4], Step [8000/12500], Loss: 1.2325\n",
      "Epoch [3/4], Step [10000/12500], Loss: 1.6902\n",
      "Epoch [3/4], Step [12000/12500], Loss: 0.9487\n",
      "Epoch [4/4], Step [2000/12500], Loss: 1.2107\n",
      "Epoch [4/4], Step [4000/12500], Loss: 1.6800\n",
      "Epoch [4/4], Step [6000/12500], Loss: 1.9871\n",
      "Epoch [4/4], Step [8000/12500], Loss: 2.3231\n",
      "Epoch [4/4], Step [10000/12500], Loss: 1.0729\n",
      "Epoch [4/4], Step [12000/12500], Loss: 1.1677\n"
     ]
    }
   ],
   "source": [
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
    "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 2000 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e565dbe3-f0f4-4c29-bdc9-9c33a8a815e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Accuracy of the network: 45.66 %\n",
      "Accuracy of plane: 68.5 %\n",
      "Accuracy of car: 71.1 %\n",
      "Accuracy of bird: 25.0 %\n",
      "Accuracy of cat: 22.9 %\n",
      "Accuracy of deer: 48.1 %\n",
      "Accuracy of dog: 45.2 %\n",
      "Accuracy of frog: 46.7 %\n",
      "Accuracy of horse: 47.1 %\n",
      "Accuracy of ship: 32.4 %\n",
      "Accuracy of truck: 49.6 %\n"
     ]
    }
   ],
   "source": [
    "print('Finished Training')\n",
    "PATH = './cnn.pth'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_kernel",
   "language": "python",
   "name": "pytorch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
